---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r set up, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```

# metasim

The goal of metasim is to simulate meta-analysis data. 

I found I was rewriting the same types of analyses. I got to thinking how to make a modular set of tools for simulating meta-anlaysis data. 

In particular, I'm interested in simulating for different values of 

- $k$, number of studies
- $\tau$ variation between studies
- $\varepsilon$ variation within a study
- numbers of trials
- distributions, _and_ parameters; e.g., $\exp(\lambda = 1)$ and $\exp(\lambda = 2)$. 

## work in progress

This package is a work in progress, can't guarantee anything works as intended.  

## installation

You can install metasim from github with:

```{r gh-installation, eval = FALSE}
# install.packages("devtools")
devtools::install_github("softloud/metasim")
```

## examples


### simulate paired sample sizes

```{r packages, message=FALSE}
# packages
library(metasim)
library(tidyverse)

# so these results are reproducible
set.seed(38) 

# I like to set.seed with my age. It makes me feel smug that I'm a middle-aged woman who codes. 

```


This is a function I have often wished I've had on hand when simulating meta-analysis data. Thing is, running, say, 1000 simulations, I want to do this for the _same_ sample sizes. So, I need to generate the sample sizes for each study and for each group (control or intervention).   

Given a specific $k$, generate a set of sample sizes. 

```{r different k}

# defaults to k = 3
meta_n()

meta_n(k = 3)

# set k to a different value

meta_n(k = 6) 


```

Suppose we require data that mimics small cohorts, say as small as 3, and as large as 50. 

```{r small cohort}
# control upper and lower bounds
meta_n(min_n = 3, max_n = 50)
 
```

We expect cohorts from the same study to have roughly the same size, proportional to that size. We can control this proportion with the `prop` argument.

Suppose we wish to mimic data for which the cohorts are almost exactly the same (say becaues of classes of undergrads being split in half and accounting for dropouts).

```{r prop}
# small variation between sample sizes of studies
meta_n(k = 2, prop = 0.05, max_n = 50)

```

It can be useful, for more human-interpretable purposes, to display the sample sizes in wide format. 

This is also useful for calculations that convert two measures to one, say, the standardised mean difference of the control and intervention groups. 

Consider four classrooms of children, who may have one or two away for illness.

```{r wide n}
meta_n(k = 4, prop = 0.05, max_n = 30, wide = TRUE) %>%
  # from here I'm just relabelling the class variable for prettiness
  separate(study, into = c("remove", "class"), sep = "_") %>% 
  select(-remove) %>% 
  mutate(class = letters[as.numeric(class)])
```


### simulation parameters

Adding a few values of $\tau$, different numbers of studies $k$, and so forth can ramp up the number of combinations of simulation parameters very quickly.  

I haven't settled on a _way_ of simulating data, and haven't found heaps in the way of guidance yet. So, this is all a bit experimental. My guiding star is packaging what I'd use right now. 

What I do always end up with is generating a dataset that summarises what I would like to iterate over in simulation. 

The `sim_df` takes user inputs for distributions, numbers of studies, between-study error $\tau$, within-study error $\varepsilon$, and the proportion $\rho$ of sample size we expect the sample sizes to different within study cohorts.

```{r}
# defaults
sim_df()

sim_df() %>%   str(1)

# only consider small values of k
sim_df(k = c(2, 5, 7)) %>% str(1)
```

For the list-column of tibbles `n`, the `sim_df` function calls `meta_n` and generates a set of sample sizes based on the value in the column `k`.

```{r}
demo_k <- sim_df() 

# the variable n is a list-column of tibbles
demo_k %>% pluck("n") %>% head(3)


# compare the number of rows in the dataframe in the n column with the k value
# divide by two because there are two rows for each study,
# one for each group, control and intervention
demo_k %>% pluck("n") %>% map_int(nrow) %>% head(3) / 2
demo_k %>% pluck("k") %>% head(3)

```






