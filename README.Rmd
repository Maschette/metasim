---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```

# metasim

The goal of metasim is to simulate meta-analysis data. 

I found I was rewriting the same types of analyses. I got to thinking how to make a modular set of tools for simulating meta-anlaysis data. 

In particular, I'm interested in simulating for different 
- $k$, number of studies
- $\tau$ variation between studies
- $\epsilon$ variation within a study
- numbers of trials
- distributions, and multiple sets of parameters

## work in progress

This package is a work in progress, not intended for public consumption. 

## installation

You can install metasim from github with:

```{r gh-installation, eval = FALSE}
# install.packages("devtools")
devtools::install_github("softloud/metasim")
```

## Examples

```{r packages}
library(metasim)
```


This is a function I have often wished I've had on hand when simulating meta-analysis data. Thing is, running, say, 1000 simulations, I want to do this for the _same_ sample sizes. So, I need to generate the sample sizes for each study and for each group (control or intervention).   

Given a specific $k$, generate a set of sample sizes. 

```{r different k}

# defaults to k = 3
meta_n()

meta_n(k = 3)

# set k to a different value

meta_n(k = 6) 


```

Suppose we require data that mimics small cohorts, say as small as 3, and as large as 50. 

```{r small cohort}
# control upper and lower bounds
meta_n(min_n = 3, max_n = 50)
 
```

We expect cohorts from the same study to have roughly the same size, proportional to that size. We can control this proportion with the `prop` argument.

Suppose we wish to mimic data for which the cohorts are almost exactly the same (say becaues of classes of undergrads being split in half and accounting for dropouts).

```{r prop}
# small variation between sample sizes of studies
meta_n(k = 2, prop = 0.1)

```


